import torch
from diffusers import QwenImageEditPlusPipeline
from diffusers.utils import load_image
from sdnq import SDNQConfig  # import sdnq to register it into diffusers and transformers
from sdnq.common import use_torch_compile as triton_is_available
from sdnq.loader import apply_sdnq_options_to_model


pipe = QwenImageEditPlusPipeline.from_pretrained(
    "Disty0/Qwen-Image-Edit-2511-SDNQ-uint4-svd-r32", torch_dtype=torch.bfloat16
)
pipe.enable_model_cpu_offload()

image1 = load_image(
    "https://huggingface.co/datasets/OzzyGT/diffusers-examples/resolve/main/qwen-image-edit-plus/20251223141129.png"
)
image2 = load_image(
    "https://huggingface.co/datasets/OzzyGT/diffusers-examples/resolve/main/qwen-image-edit-plus/20251223141332.png"
)

prompt = "the martial artist turtle from image 1 and the boxer rabbit from image 2 are fighting in an epic battle scene at a beach of a tropical island, 35mm, depth of field, 50mm lens, f/3.5, cinematic lighting"

output = pipe(
    image=[image1, image2],
    prompt=prompt,
    negative_prompt=" ",
    true_cfg_scale=4.0,
    num_inference_steps=40,
    generator=torch.Generator("cuda").manual_seed(42),
)
output_image = output.images[0]
output_image.save("qwen-image-edit-2511-sdnq-uint4-svd-r32.png")
